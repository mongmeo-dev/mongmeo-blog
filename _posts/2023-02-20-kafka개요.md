---
Layout: post
title: Kafka 개요
subtitle: 카프카란 무엇일까?
tags: [MQ, Kakfa]
---

# Kafka 개요

## MQ(Message Queue)

[tecoble](https://tecoble.techcourse.co.kr/post/2021-09-19-message-queue/)에 잘 정리되어있다.

> 메시지 큐(Message Queue)는 프로세스 또는 프로그램 간에 데이터를 교환할 때 사용하는 통신 방법 중에 하나로, 메시지 지향 미들웨어(Message Oriented Middleware:MOM)를 구현한 시스템을 의미한다. 메시지 지향 미들웨어란 비동기 메시지를 사용하는 응용 프로그램들 사이에서 데이터를 송수신하는 것을 의미한다. 여기서 메시지란 요청, 응답, 오류 메시지 혹은 단순한 정보 등의 작은 데이터가 될 수 있다.

메시지를 보내는 쪽을 'Producer(혹은 생산자)', 받는 쪽을 'Consumer(혹은 소비자)'라고 한다.

생산자는 메시지를 발행하고 MessageQueue에 넣는다. 이 때 중요한 점은 발행 후 소비자가 메시지를 처리하는 시점이 보장되지 않는 것이다.

메시지를 발행하고 MQ에 넣은 생산자는 소비자가 메시지를 처리했는지에 대해 신경쓰지 않고(물론 동기 통신도 가능하긴 하다) 다음 작업을 실행한다.

소비자는 MQ에서 메시지를 꺼내 처리한다.

## Kafka

### Event Streaming Platform

> Apache Kafka는 별도의 시작이나 끝이 없는 스트리밍 이벤트 데이터 또는 일반 데이터를 수집, 처리, 저장하는 데 널리 사용되는 이벤트 스트리밍 플랫폼입니다. Kafka는 차세대 분산 애플리케이션이 확장을 통해 스트리밍 이벤트를 분당 수십억 개까지 처리할 수 있도록 합니다.
>
> [GCP - Apache Kafka란?](https://cloud.google.com/learn/what-is-apache-kafka?hl=ko)

위 글에서 나와있듯이 Kafka는 단순한 MessageQueue가 아닌 이벤트 스트리밍 플랫폼이다.

메시지 브로커와 이벤트 브로커의 가장 큰 차이점은 메시지 저장 유무이다.

메시지 브로커는 소비자가 메시지를 받고 처리하면 해당 메시지를 제거한다. 이벤트 브로커는 받은 이벤트 (혹은 메시지)를 제거하지 않고 보관한다. 메시지를 보관함으로써 장애 발생시 해당 지점부터 다시 시도할 수 있다는 이점을 가진다.

### RebbitMQ와 Kafka의 메시지 전달 구조

**RebbitMQ**부터 살펴보자.

RebbitMQ는 생산자로부터 메시지를 받으면 'exchanger(교환기)'가 메시지의 수신자를 확인하고 해당 소비자의 메시지 큐에 메시지를 넣는다. 
소비자는 자신의 메시지 큐를 체크하다가 메시지가 들어오면 메시지를 처리한다.

교환기가 메시지를 처리함으로써 메시지가 수신자의 큐에 정확히 전달할 수 있게 되고, 메시지 데이터 유실의 염려가 없어진다.

하지만 모든 메시지가 교환기를 거치고, 교환기는 수신자를 판단하여 보내기 때문에 교환기에 부하가 많이 걸리게 된다.

이제 **Kafka**는 메시지(이벤트)를 어떻게 전달하는지 알아보자.

Kafka는 교환기를 사용하지 않는다.

Kafka 브로커에 들어온 메시지는 소비자 큐(topic, 이후에 살펴본다.)에 저장되고, 소비자는 구독하고 있는 토픽의 메시지를 꺼내온다.

## 일단 해보자 Kafka

일단 로컬에 카프카를 다운받자.

```bash
brew install wget
wget https://archive.apache.org/dist/kafka/3.3.1/kafka_2.13-3.3.1.tgz
tar xvf kafka_2.13-3.3.1.tgz
mv kafka_2.13-3.3.1 kafka
rm -f kafka_2.13-3.3.1.tgz
```

터미널을 열고, 카프카를 다운받을 폴더로 이동한 뒤 위 스크립트를 실행한다.

```bash
ls
> kafka
```

해당 폴더에 kafka 폴더가 생기면 정상적으로 완료된 것이다.

카프카 브로커와 주키퍼는 구축해놓았다. 접속 정보는 아래와 같다.

* 카프카

| 내부 IP       | 플로팅 IP      |
| ------------- | -------------- |
| 192.168.0.148 | 103.218.158.43 |

카프카를 통해 메시지를 보내기 위해서는 '토픽'을 생성해야한다.

카프카에서는 메시지를 발행할 때 특정 토픽으로 발행하고, 소비자는 특정 토픽을 구독하고 있다가 메시지가 들어오면 소비한다.

위에서 다운로드 받은 kafka 폴더로 이동하고 아래 명령어를 입력해보자.

```bash
bin/kafka-topics.sh --bootstrap-server 103.218.158.43:9092 \
--create --topic 토픽이름 \
--partitions 3 --replication-factor 1
```

kafka/bin 폴더 내에는 콘솔로 카프카의 여러 기능들을 사용할 수 있는 쉘 스크립트가 들어있다. 여기서는 토픽을 관리하기 위한 스크립트인 kafka-topics.sh를 사용한다.

옵션을 살펴보자.

* --bootstrap-server 103.218.158.43:9092 : 카프카 브로커의 접속 정보를 입력한다.
* --create -- topic (토픽이름) : (토픽이름)을 이름으로 가지는 토픽을 생성한다.
* --partitions 3 : 카프카에서는 병렬 처리를 위해 토픽을 파티션을 이용해 구성한다. 한 토픽에 여러 파티션이 존재할 수 있으며, 파티션의 개수를 늘리는 기능은 지원하지만 줄이는 기능은 지원하지 않으니 적은 수의 파티션으로 시작하여 필요 시 추가로 늘리는 것을 추천한다.
* --replication-factor 1 : 안정적인 운영을 위해 토픽의 데이터를 복사할 수를 정한다. 이 예제에서는 1개로 설정했지만, 실제 운영환경에서는 추천하지 않는다. 참고로 토픽을 복사하는 것이 아닌 토픽 내의 파티션을 복제한다.

토픽을 생성하였다면 producer와 consumer를 실행시키고 메시지를 보내보자.

터미널을 2개 실행한다.

(터미널1)

```bash
bin/kafka-console-producer.sh \
--bootstrap-server 103.218.158.43:9092 \
--topic 토픽이름 \
--property "parse.key=true" --property "key.separator=:"
```

카프카를 통해 메시지를 보내보기 위해 생산자를 실행한다. 옵션을 살펴보자.

* --bootstrap-server 103.218.158.43:9092 : 카프카 브로커의 접속 정보를 입력한다.
* --topic (토픽이름) : 메시지를 발행할 토픽을 선택한다.
* --property "parse.key=true" --property "key.separator=:" : 카프카에서는 메시지를 발행할 때 메시지의 키를 지정할 수 있다. parse.key 옵션을 true로 설정하면 key를 사용하겠다는 것이고, key.separator의 값으로 전송한 메시지를 나누어 파싱한다. (위 예시에서 'hello:world'라는 메시지를 발행하면 key는 hello, value는 world인 메시지가 발행된다)

위 명령을 실행하면 아래처럼 메시지를 입력할 수 있는 상태가 된다.

```bash
>
```

이번엔 생성한 토픽을 구독하는 소비자를 실행시켜보자.

(터미널2)

```bash
bin/kafka-console-consumer.sh --bootstrap-server 103.218.158.43:9092 --topic 토픽이름
```

옵션 설명은 생략한다.

위 명령어를 입력하면 구독하고 있는 토픽에 메시지가 들어오기를 기다린다.

생산자가 실행되어있는 터미널에서 메시지를 입력해보자.

(터미널1)

```bash
> message1:hello
```

메시지를 입력하고 소비자를 확인하면 메시지가 도착한 것을 확인할 수 있다.

(터미널2)

```bash
hello
```

토픽을 생성하고 토픽으로 메시지를 발행하고 토픽을 구독하는 것을 실습해보았다.

다음 글에서는 카프카의 이론적인 부분을 다뤄볼 예정이다.